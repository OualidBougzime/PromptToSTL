# üöÄ Batch Runner - Ex√©cution Automatique de Prompts CAD

Ce module permet d'ex√©cuter automatiquement plusieurs prompts CAD et de sauvegarder tous les r√©sultats (logs, code g√©n√©r√©, fichiers STL).

## üìã Fonctionnalit√©s

- ‚úÖ Ex√©cution automatique de 8 prompts CAD pr√©d√©finis
- üìù Sauvegarde des logs d'ex√©cution pour chaque prompt
- üíæ Sauvegarde du code Python g√©n√©r√© pour chaque prompt
- üìä G√©n√©ration d'un rapport JSON avec tous les r√©sultats
- ‚è±Ô∏è Mesure du temps d'ex√©cution pour chaque prompt
- üéØ R√©sum√© des succ√®s/√©checs √† la fin

## üéØ Utilisation Rapide

### Option 1: Script Bash (recommand√©)

```bash
./run_batch.sh
```

### Option 2: Script Python Direct

```bash
python3 batch_runner.py
```

## üìÇ Structure des Fichiers G√©n√©r√©s

Apr√®s l'ex√©cution, un dossier `batch_results/` est cr√©√© avec:

```
batch_results/
‚îú‚îÄ‚îÄ batch_run_YYYYMMDD_HHMMSS.log      # Logs complets de l'ex√©cution
‚îú‚îÄ‚îÄ batch_results_YYYYMMDD_HHMMSS.json # R√©sultats structur√©s (JSON)
‚îú‚îÄ‚îÄ prompt_01_code.py                   # Code g√©n√©r√© pour le prompt 1
‚îú‚îÄ‚îÄ prompt_02_code.py                   # Code g√©n√©r√© pour le prompt 2
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ prompt_08_code.py                   # Code g√©n√©r√© pour le prompt 8
```

Les fichiers STL g√©n√©r√©s sont dans `backend/output/`.

## üìä Format du Fichier JSON de R√©sultats

Le fichier `batch_results_*.json` contient:

```json
{
  "timestamp": "20250113_143022",
  "total_prompts": 8,
  "successful": 7,
  "failed": 1,
  "results": [
    {
      "index": 1,
      "prompt": "Create a table: make a rectangular...",
      "start_time": "2025-01-13T14:30:22.123456",
      "end_time": "2025-01-13T14:30:45.789012",
      "execution_time_seconds": 23.67,
      "success": true,
      "code": "# Code Python g√©n√©r√©...",
      "stl_path": "/path/to/generated.stl",
      "error": null,
      "logs": [
        "[Progress 10%] Analyzing prompt...",
        "[Progress 50%] Generating code...",
        "[Progress 100%] Complete!"
      ]
    }
  ]
}
```

## üé® Personnalisation des Prompts

### M√©thode 1: Modifier `prompts.json`

√âditez le fichier `prompts.json` pour ajouter/modifier/d√©sactiver des prompts:

```json
{
  "prompts": [
    {
      "id": 1,
      "name": "Mon Objet",
      "enabled": true,
      "prompt": "Votre prompt personnalis√© ici..."
    }
  ]
}
```

Puis mettez √† jour `batch_runner.py` pour lire depuis ce fichier:

```python
# Au lieu de la liste PROMPTS hardcod√©e, ajoutez:
import json

with open('prompts.json', 'r') as f:
    config = json.load(f)
    PROMPTS = [p['prompt'] for p in config['prompts'] if p['enabled']]
```

### M√©thode 2: Modifier directement `batch_runner.py`

√âditez la liste `PROMPTS` au d√©but du fichier:

```python
PROMPTS = [
    "Votre premier prompt...",
    "Votre deuxi√®me prompt...",
    # etc.
]
```

## üîß Configuration

### Pr√©requis

1. **Ollama** doit √™tre install√© et en cours d'ex√©cution
   ```bash
   ollama serve
   ```

2. **Mod√®les Ollama** requis:
   ```bash
   ollama pull qwen2.5:7b
   ollama pull qwen2.5:14b
   ollama pull qwen2.5-coder:7b
   ollama pull qwen2.5-coder:14b
   ollama pull deepseek-coder:6.7b
   ollama pull deepseek-coder:33b
   ```

3. **D√©pendances Python**:
   ```bash
   pip install -r requirements.txt
   ```

## üìà Exemple de Sortie

```
==========================================
  PromptToSTL Batch Runner
==========================================

üöÄ Starting batch run with 8 prompts...
   Processing 8 CAD prompts
   Results will be saved to: ./batch_results/

================================================================================
[1/8] Processing prompt:
  Create a table: make a rectangular top 200 mm √ó 100 mm √ó 15 mm, add four...
================================================================================

  [Progress 10%] Analyzing prompt structure...
  [Progress 30%] Generating CAD code...
  [Progress 70%] Validating code...
  [Progress 100%] Executing and generating STL...
  ‚úÖ Success! STL saved to: backend/output/generated_table.stl
  üìù Code saved to: batch_results/prompt_01_code.py
  ‚è±Ô∏è  Execution time: 12.34s

================================================================================
[2/8] Processing prompt:
  Create a vase by revolving a smooth profile...
================================================================================

...

================================================================================
BATCH RUN SUMMARY
================================================================================
Total prompts: 8
Successful:    7 ‚úÖ
Failed:        1 ‚ùå
Total time:    156.78s
Average time:  19.60s per prompt
================================================================================

‚úÖ Batch execution completed successfully!
üìÅ Check the batch_results/ folder for:
   - Execution logs (.log files)
   - Results summary (.json files)
   - Generated code (.py files)
   - STL files (in backend/output/)
```

## üêõ D√©pannage

### Probl√®me: "Module not found"
```bash
pip install -r requirements.txt
```

### Probl√®me: "Ollama not found"
Installez Ollama depuis https://ollama.ai et lancez:
```bash
ollama serve
```

### Probl√®me: √âchec de certains prompts
- Consultez le fichier `.log` pour les d√©tails
- V√©rifiez que les mod√®les Ollama sont bien t√©l√©charg√©s
- Certains prompts complexes (comme Stanford Bunny) peuvent n√©cessiter plus de ressources

## üéØ Exemples d'Utilisation

### Ex√©cuter seulement certains prompts

Modifiez la liste `PROMPTS` dans `batch_runner.py`:

```python
PROMPTS = [
    "Create a table: ...",  # Garder celui-ci
    # "Create a vase: ...",  # Commenter pour sauter
]
```

### Lancer en mode silencieux

```bash
python3 batch_runner.py > /dev/null 2>&1
```

### Surveiller l'ex√©cution en temps r√©el

```bash
./run_batch.sh | tee batch_execution.log
```

## üìö Ressources

- [Documentation PromptToSTL](README.md)
- [Exemples de prompts](frontend/app.js)
- [Documentation CadQuery](https://cadquery.readthedocs.io/)

## ü§ù Contribution

Pour ajouter de nouveaux prompts de test:
1. Ajoutez-les dans `prompts.json` ou `PROMPTS` dans `batch_runner.py`
2. Testez avec `./run_batch.sh`
3. Partagez vos r√©sultats!

---

**Note**: L'ex√©cution compl√®te des 8 prompts peut prendre entre 2 et 20 minutes selon la complexit√© et les performances de votre machine.
