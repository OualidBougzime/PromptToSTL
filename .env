HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# ===== MULTI-AGENT SYSTEM CONFIGURATION =====

# Ollama Configuration (Local LLM) - Pour Design Expert & Self-Healing
# Assurez-vous qu'Ollama est lancé: ollama serve
OLLAMA_BASE_URL=http://localhost:11434

# Design Expert Agent - Validation des règles métier
# Modèles recommandés: qwen2.5-coder:7b, codellama:7b, llama3.1:8b
DESIGN_EXPERT_MODEL=qwen2.5-coder:7b

# Self-Healing Agent - Correction automatique de code
# Modèles recommandés: deepseek-coder:6.7b, codellama:7b, qwen2.5-coder:7b
CODE_LLM_MODEL=deepseek-coder:6.7b

# ===== CHAIN-OF-THOUGHT AGENTS (OpenAI) =====
# Pour génération universelle de N'IMPORTE QUELLE forme
# Obtenez votre clé API sur: https://platform.openai.com/api-keys

OPENAI_API_KEY=sk-your-openai-api-key-here

# Chain-of-Thought Models (recommandé: gpt-4 pour meilleure qualité)
COT_ARCHITECT_MODEL=gpt-4
COT_PLANNER_MODEL=gpt-4
COT_SYNTHESIZER_MODEL=gpt-4

# Alternative moins chère mais moins performante:
# COT_ARCHITECT_MODEL=gpt-3.5-turbo
# COT_PLANNER_MODEL=gpt-3.5-turbo
# COT_SYNTHESIZER_MODEL=gpt-4

# Multi-Agent System Settings
MAX_RETRIES=3
AGENT_TIMEOUT=30
