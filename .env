HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# ===== MULTI-AGENT SYSTEM CONFIGURATION =====

# Ollama Configuration (Local LLM) - Pour Design Expert & Self-Healing
# Assurez-vous qu'Ollama est lancé: ollama serve
OLLAMA_BASE_URL=http://localhost:11434

# Design Expert Agent - Validation des règles métier
# Modèles recommandés: qwen2.5-coder:7b, codellama:7b, llama3.1:8b
DESIGN_EXPERT_MODEL=qwen2.5-coder:7b

# Self-Healing Agent - Correction automatique de code
# Modèles recommandés: deepseek-coder:6.7b, codellama:7b, qwen2.5-coder:7b
CODE_LLM_MODEL=deepseek-coder:6.7b

# ===== CHAIN-OF-THOUGHT AGENTS (Ollama) =====
# Pour génération universelle de N'IMPORTE QUELLE forme
# Modèles open-source locaux via Ollama

# Architect Agent - Raisonnement et analyse (meilleurs modèles: qwen2.5:14b, llama3.1:8b)
COT_ARCHITECT_MODEL=qwen2.5:14b

# Planner Agent - Planification détaillée (meilleurs modèles: qwen2.5-coder:14b, codellama:13b)
COT_PLANNER_MODEL=qwen2.5-coder:14b

# Synthesizer Agent - Génération de code (meilleurs modèles: deepseek-coder:33b, qwen2.5-coder:14b)
COT_SYNTHESIZER_MODEL=deepseek-coder:33b

# Alternatives plus légères (moins de RAM, mais moins performant):
# COT_ARCHITECT_MODEL=qwen2.5:7b
# COT_PLANNER_MODEL=qwen2.5-coder:7b
# COT_SYNTHESIZER_MODEL=deepseek-coder:6.7b

# Multi-Agent System Settings
MAX_RETRIES=3
AGENT_TIMEOUT=30
